from __future__ import annotations
import argparse, json, hashlib
from pathlib import Path

from .io_utils import RUNS_ROOT, ensure_dir, write_json, write_yaml, write_text
from .parser import prompt_to_scenario
from .utils import timestamp_slug, slugify, git_hash_fallback
from . import __version__

# Optional modules (present in your repo; guard just in case)
try:
	from .rollout import run_batch
except Exception:
	run_batch = None  # type: ignore

try:
	from .metrics import aggregate, write_summary
except Exception:
	aggregate = None  # type: ignore
	write_summary = None  # type: ignore

try:
	from .reporter import write_report
except Exception:
	write_report = None  # type: ignore

try:
	from .coverage import build_coverage   # taxonomy coverage
except Exception:
	build_coverage = None  # type: ignore

try:
	from .report_html import generate_report
except Exception:
	generate_report = None  # type: ignore

try:
	from .schema_validate import validate_scenario  # (ok if missing)
except Exception:
	validate_scenario = None  # type: ignore

from .sim_one import run_one

def _make_run_dir(prompt: str, name: str | None) -> Path:
	stamp = timestamp_slug()
	label = slugify(name or prompt)
	run_dir = RUNS_ROOT / f"{stamp}_{label}"
	ensure_dir(run_dir)
	return run_dir

def _write_core_files(run_dir: Path, prompt: str, n_runs: int, seed_base: int, scn: dict) -> dict:
	seeds = {"base_seed": seed_base, "seeds": [seed_base + i for i in range(n_runs)]}
	manifest = {
		"prompt": prompt,
		"n_runs": n_runs,
		"seed_base": seed_base,
		"version": __version__,
		"git": git_hash_fallback(),
	}
	write_yaml(run_dir / "scenario.yaml", scn)
	write_json(run_dir / "seeds.json", seeds)
	write_json(run_dir / "manifest.json", manifest)

	# Optional: schema validation & context summary
	if validate_scenario is not None:
		try:
			ok, errors, summary = validate_scenario(scn)
			write_json(run_dir / "validation.json", {"ok": bool(ok), "errors": list(errors or []), "context_summary": summary or {}})
		except Exception as e:
			write_json(run_dir / "validation.json", {"ok": False, "errors": [f"validator exception: {type(e).__name__}: {e}"], "context_summary": {}})
	return {"seeds": seeds, "manifest": manifest}

def cmd_simulate(args: argparse.Namespace) -> int:
	prompt: str = args.prompt
	n_runs: int = int(args.runs)
	seed_base: int = int(args.seed)
	scn = prompt_to_scenario(prompt, n_runs=n_runs)
	run_dir = _make_run_dir(prompt, args.name)
	_write_core_files(run_dir, prompt, n_runs, seed_base, scn)
	write_text(run_dir / "RUN_README.md", """# EdgeSim Run (V0 Step 1)

This folder was generated by `edgesim simulate`.

**Includes:**
- `scenario.yaml`
- `seeds.json`
- `manifest.json`
- `validation.json` (if validator available)
""")
	status = " (schema validated)" if (run_dir / "validation.json").exists() else ""
	print(f"\n[EdgeSim] Created run @ {run_dir}\n- scenario.yaml\n- seeds.json\n- manifest.json\n- validation.json{status}\n")
	return 0

def cmd_run_batch(args: argparse.Namespace) -> int:
	if run_batch is None:
		raise SystemExit("Batch runner modules not available. Add rollout/metrics/reporter or skip this command.")

	prompt: str = args.prompt
	n_runs: int = int(args.runs)
	seed_base: int = int(args.seed)
	profile: str = args.profile

	# Parse and prep
	scn = prompt_to_scenario(prompt, n_runs=n_runs)
	run_dir = _make_run_dir(prompt, args.name)
	files = _write_core_files(run_dir, prompt, n_runs, seed_base, scn)
	seeds = files["seeds"]["seeds"]

	# Execute batch
	if hasattr(args, "time_budget_min") or hasattr(args, "auto_degrade"):
		try:
			run_batch(prompt, scn, seeds, run_dir, profile=profile,
			          time_budget_min=getattr(args, "time_budget_min", None),
			          auto_degrade=bool(getattr(args, "auto_degrade", False)))
		except TypeError:
			run_batch(prompt, scn, seeds, run_dir, profile=profile)
	else:
		run_batch(prompt, scn, seeds, run_dir, profile=profile)

	# Coverage
	coverage = {}
	if build_coverage is not None:
		try:
			coverage = build_coverage(run_dir / "per_run")
		finally:
			write_json(run_dir / "coverage.json", coverage)

	# Summary
	if aggregate is not None:
		summary = aggregate(run_dir / "per_run")
	else:
		summary = {"runs": 0, "successes": 0, "failures": 0, "avg_time": 0.0, "avg_steps": 0}
	if write_summary is not None:
		write_summary(run_dir, summary)

	# Legacy Markdown
	if write_report is not None:
		write_report(run_dir, prompt, files["manifest"], coverage, summary)

	# HTML report
	if generate_report is not None:
		try:
			out_html = generate_report(run_dir)
			print(f"[EdgeSim] HTML report: {out_html}")
		except Exception as e:
			print(f"[EdgeSim][WARN] Failed to generate HTML report: {e}")

	print(f"\n[EdgeSim] Batch done @ {run_dir}\n- per_run/*.csv\n- summary.json\n- coverage.json\n- report.md\n- report.html\n")
	return 0

def cmd_run_one(args: argparse.Namespace) -> int:
	prompt: str = args.prompt
	gui: bool = bool(args.gui)
	realtime: bool = bool(args.realtime)
	scn = prompt_to_scenario(prompt, n_runs=1)
	run_dir = _make_run_dir(prompt, args.name)
	_write_core_files(run_dir, prompt, 1, args.seed, scn)
	out = run_one(prompt, scn, run_dir, dt=0.05, realtime=realtime, gui=gui)
	print(f"\n[EdgeSim] Single rollout @ {run_dir}\n- success={out['success']} time={out['time']:.2f}s steps={out['steps']}\n- run_one.csv\n")
	return 0

# ---- NEW: verify command (digest checks) ----
def _sha256_file(path: Path) -> str:
	h = hashlib.sha256(); h.update(path.read_bytes()); return h.hexdigest()

def _digest_csvs(per_run_dir: Path) -> str:
	h = hashlib.sha256()
	for p in sorted(per_run_dir.rglob("*.csv")):
		h.update(p.read_bytes())
	return h.hexdigest()

def cmd_verify(args: argparse.Namespace) -> int:
	batch_dir = Path(args.batch).resolve()
	man_path = batch_dir / "manifest.json"
	if not man_path.exists():
		raise SystemExit(f"manifest.json not found in {batch_dir}")
	try:
		man = json.loads(man_path.read_text(encoding="utf-8"))
	except Exception as e:
		raise SystemExit(f"manifest.json unreadable: {e}")

	expect_csv = man.get("per_run_digest", "NA")
	got_csv = _digest_csvs(batch_dir / "per_run") if (batch_dir / "per_run").exists() else "NA"
	ok_csv = (expect_csv != "NA") and (expect_csv == got_csv)

	expect_world = man.get("world_sha256", "NA")
	got_world = "NA"
	world_path = batch_dir / "world.json"
	
	if not world_path.exists():
		# fallback: grab the first per-run world.json if present
		pr = batch_dir / "per_run"
		for sub in sorted(pr.glob("run_*")):
			cand = sub / "world.json"
			if cand.exists():
				world_path = cand
				break


	if world_path.exists():
		got_world = hashlib.sha256(world_path.read_bytes()).hexdigest()
	ok_world = (expect_world != "NA") and (expect_world == got_world)

	print("[edgesim verify]")
	print(f"- CSV digest: expected={expect_csv[:12]}…  got={got_csv[:12]}…   -> {'PASS' if ok_csv else 'FAIL'}")
	if expect_world == "NA" and not world_path.exists():
		print(f"- world.json: expected=NA  got=NA -> SKIP")
	else:
		print(f"- world.json: expected={expect_world[:12]}…  got={got_world[:12]}… -> {'PASS' if ok_world else 'FAIL'}")

	return 0 if (ok_csv and (ok_world or expect_world=='NA')) else 1

def build_parser() -> argparse.ArgumentParser:
	p = argparse.ArgumentParser(prog="edgesim", description="EdgeSim V0 CLI")
	sub = p.add_subparsers(dest="command", required=True)

	sp = sub.add_parser("simulate", help="Parse prompt → Scenario Graph & create run folder")
	sp.add_argument("prompt", type=str)
	sp.add_argument("--runs", type=int, default=100)
	sp.add_argument("--seed", type=int, default=42)
	sp.add_argument("--name", type=str, default=None)
	sp.set_defaults(func=cmd_simulate)

	sb = sub.add_parser("run-batch", help="Seeded batch → CSVs + summary + report")
	sb.add_argument("prompt", type=str)
	sb.add_argument("--runs", type=int, default=100)
	sb.add_argument("--seed", type=int, default=42)
	sb.add_argument("--name", type=str, default=None)
	sb.add_argument("--profile", type=str, default="minimal", choices=["minimal", "robot", "full"])
	sb.add_argument("--time-budget-min", type=float, default=None,
	                help="Soft wall-clock budget (minutes). If ETA exceeds and --auto-degrade is set, stop early.")
	sb.add_argument("--auto-degrade", action="store_true",
	                help="Stop early when the budget would be exceeded.")
	sb.set_defaults(func=cmd_run_batch)

	so = sub.add_parser("run-one", help="Run a single PyBullet rollout (V0)")
	so.add_argument("prompt", type=str)
	so.add_argument("--seed", type=int, default=42)
	so.add_argument("--name", type=str, default=None)
	so.add_argument("--gui", action="store_true", help="Open PyBullet GUI")
	so.add_argument("--realtime", action="store_true", help="Sleep to realtime")
	so.set_defaults(func=cmd_run_one)

	sv = sub.add_parser("verify", help="Verify reproducibility digests for a finished batch")
	sv.add_argument("batch", type=str, help="Path to runs/<batch_dir>")
	sv.set_defaults(func=cmd_verify)

	return p

def main() -> int:
	parser = build_parser()
	args = parser.parse_args()
	return args.func(args)

if __name__ == "__main__":
	exit(main())
