from __future__ import annotations
import argparse, json, hashlib
from pathlib import Path

from .io_utils import RUNS_ROOT, ensure_dir, write_json, write_yaml, write_text
from .parser import prompt_to_scenario
from .utils import timestamp_slug, slugify, git_hash_fallback
from . import __version__

# Optional modules (present in your repo; guard just in case)
try:
    from .rollout import run_batch
except Exception:
    run_batch = None  # type: ignore

try:
    from .metrics import aggregate, write_summary, calibrate_from_anchors
except Exception:
    aggregate = None  # type: ignore
    write_summary = None  # type: ignore
    calibrate_from_anchors = None  # type: ignore

try:
    from .reporter import write_report
except Exception:
    write_report = None  # type: ignore

try:
    from .coverage import build_coverage   # taxonomy coverage
except Exception:
    build_coverage = None  # type: ignore

try:
    from .report_html import generate_report
except Exception:
    generate_report = None  # type: ignore

try:
    from .schema_validate import validate_scenario  # (ok if missing)
except Exception:
    validate_scenario = None  # type: ignore

from .sim_one import run_one


def _make_run_dir(prompt: str, name: str | None) -> Path:
    stamp = timestamp_slug()
    label = slugify(name or prompt)
    run_dir = RUNS_ROOT / f"{stamp}_{label}"
    ensure_dir(run_dir)
    return run_dir

def _write_core_files(run_dir: Path, prompt: str, n_runs: int, seed_base: int, scn: dict) -> dict:
    seeds = {"base_seed": seed_base, "seeds": [seed_base + i for i in range(n_runs)]}
    manifest = {
        "prompt": prompt,
        "n_runs": n_runs,
        "seed_base": seed_base,
        "version": __version__,
        "git": git_hash_fallback(),
    }
    write_yaml(run_dir / "scenario.yaml", scn)
    write_json(run_dir / "seeds.json", seeds)
    write_json(run_dir / "manifest.json", manifest)

    # Optional: schema validation & context summary
    if validate_scenario is not None:
        try:
            ok, errors, summary = validate_scenario(scn)
            write_json(run_dir / "validation.json", {"ok": bool(ok), "errors": list(errors or []), "context_summary": summary or {}})
        except Exception as e:
            write_json(run_dir / "validation.json", {"ok": False, "errors": [f"validator exception: {type(e).__name__}: {e}"], "context_summary": {}})
    return {"seeds": seeds, "manifest": manifest}

def cmd_simulate(args: argparse.Namespace) -> int:
    prompt: str = args.prompt
    n_runs: int = int(args.runs)
    seed_base: int = int(args.seed)
    scn = prompt_to_scenario(prompt, n_runs=n_runs)
    run_dir = _make_run_dir(prompt, args.name)
    _write_core_files(run_dir, prompt, n_runs, seed_base, scn)
    write_text(run_dir / "RUN_README.md", """# EdgeSim Run (V0 Step 1)

This folder was generated by `edgesim simulate`.

**Includes:**
- `scenario.yaml`
- `seeds.json`
- `manifest.json`
- `validation.json` (if validator available)
""")
    status = " (schema validated)" if (run_dir / "validation.json").exists() else ""
    print(f"\n[EdgeSim] Created run @ {run_dir}\n- scenario.yaml\n- seeds.json\n- manifest.json\n- validation.json{status}\n")
    return 0

def cmd_run_batch(args: argparse.Namespace) -> int:
    if run_batch is None:
        raise SystemExit("Batch runner modules not available. Add rollout/metrics/reporter or skip this command.")

    prompt: str = args.prompt
    n_runs: int = int(args.runs)
    seed_base: int = int(args.seed)
    profile: str = args.profile

    # Parse and prep
    scn = prompt_to_scenario(prompt, n_runs=n_runs)
    run_dir = _make_run_dir(prompt, args.name)
    files = _write_core_files(run_dir, prompt, n_runs, seed_base, scn)
    seeds = files["seeds"]["seeds"]

    # Execute batch
    if hasattr(args, "time_budget_min") or hasattr(args, "auto_degrade"):
        try:
            run_batch(prompt, scn, seeds, run_dir, profile=profile,
                      time_budget_min=getattr(args, "time_budget_min", None),
                      auto_degrade=bool(getattr(args, "auto_degrade", False)))
        except TypeError:
            run_batch(prompt, scn, seeds, run_dir, profile=profile)
    else:
        run_batch(prompt, scn, seeds, run_dir, profile=profile)

    # Coverage
    coverage = {}
    if build_coverage is not None:
        try:
            coverage = build_coverage(run_dir / "per_run")
        finally:
            write_json(run_dir / "coverage.json", coverage)

    # Summary
    if aggregate is not None:
        summary = aggregate(run_dir / "per_run")
    else:
        summary = {"runs": 0, "successes": 0, "failures": 0, "avg_time": 0.0, "avg_steps": 0}
    if write_summary is not None:
        write_summary(run_dir, summary)

    # Legacy Markdown
    if write_report is not None:
        write_report(run_dir, prompt, files["manifest"], coverage, summary)

    # HTML report
    if generate_report is not None:
        try:
            out_html = generate_report(run_dir)
            print(f"[EdgeSim] HTML report: {out_html}")
        except Exception as e:
            print(f"[EdgeSim][WARN] Failed to generate HTML report: {e}")

    print(f"\n[EdgeSim] Batch done @ {run_dir}\n- per_run/*.csv\n- summary.json\n- coverage.json\n- report.md\n- report.html\n")
    return 0

def cmd_run_one(args: argparse.Namespace) -> int:
    prompt: str = args.prompt
    gui: bool = bool(args.gui)
    realtime: bool = bool(args.realtime)
    scn = prompt_to_scenario(prompt, n_runs=1)
    run_dir = _make_run_dir(prompt, args.name)
    _write_core_files(run_dir, prompt, 1, args.seed, scn)
    out = run_one(prompt, scn, run_dir, dt=0.05, realtime=realtime, gui=gui)
    print(f"\n[EdgeSim] Single rollout @ {run_dir}\n- success={out['success']} time={out['time']:.2f}s steps={out['steps']}\n- run_one.csv\n")
    return 0

# ---- NEW: verify command (digest checks) ----
def _sha256_file(path: Path) -> str:
    h = hashlib.sha256(); h.update(path.read_bytes()); return h.hexdigest()

def _digest_csvs(per_run_dir: Path) -> str:
    h = hashlib.sha256()
    for p in sorted(per_run_dir.rglob("*.csv")):
        h.update(p.read_bytes())
    return h.hexdigest()

def cmd_verify(args: argparse.Namespace) -> int:
    batch_dir = Path(args.batch).resolve()
    man_path = batch_dir / "manifest.json"
    if not man_path.exists():
        raise SystemExit(f"manifest.json not found in {batch_dir}")
    try:
        man = json.loads(man_path.read_text(encoding="utf-8"))
    except Exception as e:
        raise SystemExit(f"manifest.json unreadable: {e}")

    expect_csv = man.get("per_run_digest", "NA")
    got_csv = _digest_csvs(batch_dir / "per_run") if (batch_dir / "per_run").exists() else "NA"
    ok_csv = (expect_csv != "NA") and (expect_csv == got_csv)

    expect_world = man.get("world_sha256", "NA")
    got_world = "NA"
    world_path = batch_dir / "world.json"
    
    if not world_path.exists():
        # fallback: grab the first per-run world.json if present
        pr = batch_dir / "per_run"
        for sub in sorted(pr.glob("run_*")):
            cand = sub / "world.json"
            if cand.exists():
                world_path = cand
                break

    if world_path.exists():
        got_world = hashlib.sha256(world_path.read_bytes()).hexdigest()
    ok_world = (expect_world != "NA") and (expect_world == got_world)

    print("[edgesim verify]")
    print(f"- CSV digest: expected={expect_csv[:12]}…  got={got_csv[:12]}…   -> {'PASS' if ok_csv else 'FAIL'}")
    if expect_world == "NA" and not world_path.exists():
        print(f"- world.json: expected=NA  got=NA -> SKIP")
    else:
        print(f"- world.json: expected={expect_world[:12]}…  got={got_world[:12]}… -> {'PASS' if ok_world else 'FAIL'}")

    return 0 if (ok_csv and (ok_world or expect_world=='NA')) else 1

# ---- NEW: calibrate command (anchors -> metrics -> site profile + optional batch calibration.json)
def cmd_calibrate(args: argparse.Namespace) -> int:
    if calibrate_from_anchors is None:
        raise SystemExit("Calibration module not available.")

    anchors_path = Path(args.anchors).resolve()
    if not anchors_path.exists():
        raise SystemExit(f"anchors CSV not found: {anchors_path}")

    site: str = args.site
    site_profiles = RUNS_ROOT.parent / "site_profiles"
    ensure_dir(site_profiles)

    metrics = calibrate_from_anchors(anchors_path)
    site_obj = {"site": site, "anchors": str(anchors_path), "metrics": metrics}

    # write site profile
    site_profiles.mkdir(parents=True, exist_ok=True)
    site_path = site_profiles / f"{site}.json"
    write_json(site_path, site_obj)

    # optionally mirror into a batch dir so the report can render it
    if args.run is not None:
        batch_dir = Path(args.run).resolve()
        if not batch_dir.exists():
            raise SystemExit(f"--run path not found: {batch_dir}")
        write_json(batch_dir / "calibration.json", metrics)

    print(f"[EdgeSim] Calibrated site '{site}':")
    print(json.dumps(metrics, indent=2))
    print(f"- wrote {site_path}")
    if args.run is not None:
        print(f"- wrote {batch_dir / 'calibration.json'} (report will display metrics)")

    return 0


def build_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(prog="edgesim", description="EdgeSim V0 CLI")
    sub = p.add_subparsers(dest="command", required=True)

    sp = sub.add_parser("simulate", help="Parse prompt → Scenario Graph & create run folder")
    sp.add_argument("prompt", type=str)
    sp.add_argument("--runs", type=int, default=100)
    sp.add_argument("--seed", type=int, default=42)
    sp.add_argument("--name", type=str, default=None)
    sp.set_defaults(func=cmd_simulate)

    sb = sub.add_parser("run-batch", help="Seeded batch → CSVs + summary + report")
    sb.add_argument("prompt", type=str)
    sb.add_argument("--runs", type=int, default=100)
    sb.add_argument("--seed", type=int, default=42)
    sb.add_argument("--name", type=str, default=None)
    sb.add_argument("--profile", type=str, default="minimal", choices=["minimal", "robot", "full"])
    sb.add_argument("--time-budget-min", type=float, default=None,
                    help="Soft wall-clock budget (minutes). If ETA exceeds and --auto-degrade is set, stop early.")
    sb.add_argument("--auto-degrade", action="store_true",
                    help="Stop early when the budget would be exceeded.")
    sb.set_defaults(func=cmd_run_batch)

    so = sub.add_parser("run-one", help="Run a single PyBullet rollout (V0)")
    so.add_argument("prompt", type=str)
    so.add_argument("--seed", type=int, default=42)
    so.add_argument("--name", type=str, default=None)
    so.add_argument("--gui", action="store_true", help="Open PyBullet GUI")
    so.add_argument("--realtime", action="store_true", help="Sleep to realtime")
    so.set_defaults(func=cmd_run_one)

    sv = sub.add_parser("verify", help="Verify reproducibility digests for a finished batch")
    sv.add_argument("batch", type=str, help="Path to runs/<batch_dir>")
    sv.set_defaults(func=cmd_verify)

    # NEW: calibrate
    sc = sub.add_parser("calibrate", help="Compute calibration metrics from anchors CSV and write site profile")
    sc.add_argument("--anchors", required=True, help="Path to anchors.csv")
    sc.add_argument("--site", required=True, help="Site slug (filename for site_profiles/<site>.json)")
    sc.add_argument("--run", default=None, help="Optional runs/<batch_dir> to also write calibration.json for the report")
    sc.set_defaults(func=cmd_calibrate)

    return p

def main() -> int:
    parser = build_parser()
    args = parser.parse_args()
    return args.func(args)

if __name__ == "__main__":
    exit(main())
